{
    "project_name": "Angel-ML-angel",
    "violation_id": "47",
    "information": {
        "violations": [
            {
                "line": "6",
                "severity": "error",
                "message": "Line is longer than 100 characters (found 102).",
                "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
            }
        ]
    },
    "source_code": " * Copyright (C) 2017-2018 THL A29 Limited, a Tencent company. All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in\n * compliance with the License. You may obtain a copy of the License at\n *\n * https://opensource.org/licenses/Apache-2.0",
    "results": [
        {
            "tool": "styler",
            "violations": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "checkstyle_idea",
            "violations": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/47/AdaGradUpdateFunc.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/checkstyle_idea/47/AdaGradUpdateFunc.java\nindex a0204d4b30e..2e7ade3965a 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/47/AdaGradUpdateFunc.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/checkstyle_idea/47/AdaGradUpdateFunc.java\n@@ -26,62 +26,62 @@ import org.apache.commons.logging.LogFactory;\n \n public class AdaGradUpdateFunc extends OptMMUpdateFunc {\n \n-  private static final Log LOG = LogFactory.getLog(AdaGradUpdateFunc.class);\n+    private static final Log LOG = LogFactory.getLog(AdaGradUpdateFunc.class);\n \n-  public AdaGradUpdateFunc() {\n-    super();\n-  }\n+    public AdaGradUpdateFunc() {\n+        super();\n+    }\n \n-  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n-      double regL1Param, double regL2Param, int epoch) {\n-    this(matId, factor, epsilon, beta, lr, regL1Param, regL2Param, epoch, 1);\n-  }\n+    public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n+                             double regL1Param, double regL2Param, int epoch) {\n+        this(matId, factor, epsilon, beta, lr, regL1Param, regL2Param, epoch, 1);\n+    }\n \n-  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n-      double regL1Param, double regL2Param, int epoch, int batchSize) {\n-    super(matId, new int[]{factor},\n-        new double[]{epsilon, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n-  }\n+    public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n+                             double regL1Param, double regL2Param, int epoch, int batchSize) {\n+        super(matId, new int[] {factor},\n+                new double[] {epsilon, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n+    }\n \n-  @Override\n-  public void update(ServerPartition partition, int factor, double[] scalars) {\n-    double epsilon = scalars[0];\n-    double beta = scalars[1];\n-    double lr = scalars[2];\n-    double l1RegParam = scalars[3];\n-    double l2RegParam = scalars[4];\n-    double epoch = (int) scalars[5];\n-    double batchSize = (int) scalars[6];\n+    @Override\n+    public void update(ServerPartition partition, int factor, double[] scalars) {\n+        double epsilon = scalars[0];\n+        double beta = scalars[1];\n+        double lr = scalars[2];\n+        double l1RegParam = scalars[3];\n+        double l2RegParam = scalars[4];\n+        double epoch = (int) scalars[5];\n+        double batchSize = (int) scalars[6];\n \n-    for (int f = 0; f < factor; f++) {\n-      ServerRow gradientServerRow = partition.getRow(f + 2 * factor);\n-      try {\n-        gradientServerRow.startWrite();\n-        Vector weight = partition.getRow(f).getSplit();\n-        Vector square = partition.getRow(f + factor).getSplit();\n-        Vector gradient = gradientServerRow.getSplit();\n+        for (int f = 0; f < factor; f++) {\n+            ServerRow gradientServerRow = partition.getRow(f + 2 * factor);\n+            try {\n+                gradientServerRow.startWrite();\n+                Vector weight = partition.getRow(f).getSplit();\n+                Vector square = partition.getRow(f + factor).getSplit();\n+                Vector gradient = gradientServerRow.getSplit();\n \n-        if (batchSize > 1) {\n-          gradient.idiv(batchSize);\n-        }\n+                if (batchSize > 1) {\n+                    gradient.idiv(batchSize);\n+                }\n \n-        OptFuncs.iexpsmoothing2(square, gradient, beta);\n-        if (l2RegParam != 0) {\n-          gradient.iaxpy(weight, l2RegParam);\n-        }\n+                OptFuncs.iexpsmoothing2(square, gradient, beta);\n+                if (l2RegParam != 0) {\n+                    gradient.iaxpy(weight, l2RegParam);\n+                }\n \n-        OptFuncs.iadagraddelta(gradient, square, l2RegParam, lr);\n-        weight.isub(gradient);\n+                OptFuncs.iadagraddelta(gradient, square, l2RegParam, lr);\n+                weight.isub(gradient);\n \n-        if (l1RegParam != 0) {\n-          OptFuncs.iadagradthredshold(weight, square, l1RegParam, l2RegParam, lr);\n-        }\n+                if (l1RegParam != 0) {\n+                    OptFuncs.iadagradthredshold(weight, square, l1RegParam, l2RegParam, lr);\n+                }\n \n-        gradient.clear();\n-      } finally {\n-        gradientServerRow.endWrite();\n-      }\n+                gradient.clear();\n+            } finally {\n+                gradientServerRow.endWrite();\n+            }\n \n+        }\n     }\n-  }\n }\n",
            "diff_size": 47
        },
        {
            "tool": "naturalize",
            "violations": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "35",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 140).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "39",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 155).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "40",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 111).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/47/AdaGradUpdateFunc.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/naturalize/47/AdaGradUpdateFunc.java\nindex a0204d4b30e..392a5f8c329 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/47/AdaGradUpdateFunc.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/naturalize/47/AdaGradUpdateFunc.java\n@@ -32,15 +32,12 @@ public class AdaGradUpdateFunc extends OptMMUpdateFunc {\n     super();\n   }\n \n-  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n-      double regL1Param, double regL2Param, int epoch) {\n-    this(matId, factor, epsilon, beta, lr, regL1Param, regL2Param, epoch, 1);\n+  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr, double regL1Param, double regL2Param, int epoch) {\n+  this(matId, factor, epsilon, beta, lr, regL1Param, regL2Param, epoch, 1);\n   }\n \n-  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n-      double regL1Param, double regL2Param, int epoch, int batchSize) {\n-    super(matId, new int[]{factor},\n-        new double[]{epsilon, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n+  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n+    super(matId, new int[]{factor}, new double[]{epsilon, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n   }\n \n   @Override\n@@ -84,4 +81,4 @@ public class AdaGradUpdateFunc extends OptMMUpdateFunc {\n \n     }\n   }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 8
        },
        {
            "tool": "codebuff",
            "violations": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "35",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 140).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "39",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 155).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                },
                {
                    "line": "40",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 111).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/47/AdaGradUpdateFunc.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/codebuff/47/AdaGradUpdateFunc.java\nindex a0204d4b30e..f5ac97cc7e6 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/47/AdaGradUpdateFunc.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/codebuff/47/AdaGradUpdateFunc.java\n@@ -32,19 +32,17 @@ public class AdaGradUpdateFunc extends OptMMUpdateFunc {\n     super();\n   }\n \n-  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n-      double regL1Param, double regL2Param, int epoch) {\n+  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr, double regL1Param, double regL2Param, int epoch) {\n     this(matId, factor, epsilon, beta, lr, regL1Param, regL2Param, epoch, 1);\n   }\n \n-  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr,\n-      double regL1Param, double regL2Param, int epoch, int batchSize) {\n-    super(matId, new int[]{factor},\n-        new double[]{epsilon, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n+  public AdaGradUpdateFunc(int matId, int factor, double epsilon, double beta, double lr, double regL1Param, double regL2Param, int epoch, int batchSize) {\n+    super(matId, new int[]{factor}, new double[]{epsilon, beta, lr, regL1Param, regL2Param, epoch, batchSize});\n   }\n \n   @Override\n-  public void update(ServerPartition partition, int factor, double[] scalars) {\n+  public void update(\n+    ServerPartition partition, int factor, double[] scalars) {\n     double epsilon = scalars[0];\n     double beta = scalars[1];\n     double lr = scalars[2];\n@@ -52,7 +50,6 @@ public class AdaGradUpdateFunc extends OptMMUpdateFunc {\n     double l2RegParam = scalars[4];\n     double epoch = (int) scalars[5];\n     double batchSize = (int) scalars[6];\n-\n     for (int f = 0; f < factor; f++) {\n       ServerRow gradientServerRow = partition.getRow(f + 2 * factor);\n       try {\n@@ -60,28 +57,23 @@ public class AdaGradUpdateFunc extends OptMMUpdateFunc {\n         Vector weight = partition.getRow(f).getSplit();\n         Vector square = partition.getRow(f + factor).getSplit();\n         Vector gradient = gradientServerRow.getSplit();\n-\n         if (batchSize > 1) {\n           gradient.idiv(batchSize);\n         }\n-\n         OptFuncs.iexpsmoothing2(square, gradient, beta);\n         if (l2RegParam != 0) {\n           gradient.iaxpy(weight, l2RegParam);\n         }\n-\n         OptFuncs.iadagraddelta(gradient, square, l2RegParam, lr);\n         weight.isub(gradient);\n-\n         if (l1RegParam != 0) {\n           OptFuncs.iadagradthredshold(weight, square, l1RegParam, l2RegParam, lr);\n         }\n-\n         gradient.clear();\n       } finally {\n         gradientServerRow.endWrite();\n       }\n-\n     }\n   }\n-}\n+\n+}\n\\ No newline at end of file\n",
            "diff_size": 17
        },
        {
            "tool": "styler_random",
            "violations": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        },
        {
            "tool": "styler_three_grams",
            "violations": [
                {
                    "line": "6",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 102).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        }
    ],
    "repaired_by": [],
    "not_repaired_by": [
        "styler",
        "checkstyle_idea",
        "naturalize",
        "codebuff",
        "styler_random",
        "styler_three_grams"
    ]
}