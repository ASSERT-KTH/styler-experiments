{
    "project_name": "Angel-ML-angel",
    "violation_id": "1",
    "information": {
        "violations": [
            {
                "line": "15",
                "severity": "error",
                "message": "Line is longer than 100 characters (found 114).",
                "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
            }
        ]
    },
    "source_code": "\n\n  public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow, float[][] layers) {\n    super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n  }\n",
    "results": [
        {
            "tool": "styler",
            "violations": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/./experiments/projects/Angel-ML-angel/styler/05_predictions/final/files-repaired/1/LINEFirstOrderModel.java\nindex 4af089cbb97..d1cca55afd6 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/./experiments/projects/Angel-ML-angel/styler/05_predictions/final/files-repaired/1/LINEFirstOrderModel.java\n@@ -11,9 +11,8 @@ import java.util.Random;\n \n public class LINEFirstOrderModel extends EmbeddingModel {\n \n-\n-  public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow, float[][] layers) {\n-    super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n+  public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int\n+numNodeOneRow , float [][]layers) {super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n   }\n \n   @Override\n",
            "diff_size": 3
        },
        {
            "tool": "checkstyle_idea",
            "violations": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/checkstyle_idea/1/LINEFirstOrderModel.java\nindex 4af089cbb97..34143caa95c 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/checkstyle_idea/1/LINEFirstOrderModel.java\n@@ -12,102 +12,109 @@ import java.util.Random;\n public class LINEFirstOrderModel extends EmbeddingModel {\n \n \n-  public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow, float[][] layers) {\n-    super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n-  }\n-\n-  @Override\n-  public float[] dot(ByteBuf edges) {\n-\n-    Random negativeSeed = new Random(seed);\n-    IntOpenHashSet numInputs = new IntOpenHashSet();\n-\n-    int batchSize = edges.readInt();\n-    float[] partialDots = new float[batchSize * (1 + negative)];\n-    int dotInc = 0;\n-    for (int position = 0; position < batchSize; position++) {\n-      int src = edges.readInt();\n-      int dst = edges.readInt();\n-      // Skip-Gram model\n-      float[] inputs = layers[src / numNodeOneRow];\n-      int l1 = (src % numNodeOneRow) * dim;\n-      numInputs.add(src);\n-\n-      // Negative sampling\n-      int target;\n-      for (int a = 0; a < negative + 1; a++) {\n-        if (a == 0) target = dst;\n-        else do {\n-          target = negativeSeed.nextInt(maxIndex);\n-        } while (target == src);\n-\n-        numInputs.add(target);\n-        float[] outputs = layers[target / numNodeOneRow];\n-        int l2 = (target % numNodeOneRow) * dim;\n-        float f = 0.0f;\n-        for (int b = 0; b < dim; b++) f += inputs[l1 + b] * outputs[l2 + b];\n-        partialDots[dotInc++] = f;\n-      }\n+    public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow,\n+                               float[][] layers) {\n+        super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n     }\n-    this.numInputsToUpdate = numInputs.size();\n-    return partialDots;\n-  }\n-\n-  @Override\n-  public void adjust(ByteBuf dataBuf, int numInputs, int numOutputs) {\n-\n-    // used to accumulate the updates for input vectors\n-    float[] neu1e = new float[dim];\n-    float[] inputUpdates = new float[numInputs * dim];\n-    Int2IntOpenHashMap inputIndex = new Int2IntOpenHashMap();\n-    Int2IntOpenHashMap inputUpdateCounter = new Int2IntOpenHashMap();\n-    Random negativeSeed = new Random(seed);\n-    int batchSize = dataBuf.readInt();\n-\n-    for (int position = 0; position < batchSize; position++) {\n-      int src = dataBuf.readInt();\n-      int dst = dataBuf.readInt();\n-\n-      float[] inputs = layers[src / numNodeOneRow];\n-      int l1 = (src % numNodeOneRow) * dim;\n-\n-      Arrays.fill(neu1e, 0);\n-\n-      // Negative sampling\n-      int target;\n-      for (int d = 0; d < negative + 1; d++) {\n-        if (d == 0) target = dst;\n-        else do {\n-          target = negativeSeed.nextInt(maxIndex);\n-        } while (target == src);\n-\n-        float[] outputs = layers[target / numNodeOneRow];\n-        int l2 = (target % numNodeOneRow) * dim;\n-\n-        float g = dataBuf.readFloat();\n-\n-        // accumulate for the hidden layer\n-        for (int a = 0; a < dim; a++) neu1e[a] += g * outputs[a + l2];\n-        // update output layer\n-        merge(inputUpdates, inputIndex, target, inputs, g, l1);\n-        inputUpdateCounter.addTo(target, 1);\n-      }\n-\n-      // update the hidden layer\n-      merge(inputUpdates, inputIndex, src, neu1e, 1, 0);\n-      inputUpdateCounter.addTo(src, 1);\n+\n+    @Override\n+    public float[] dot(ByteBuf edges) {\n+\n+        Random negativeSeed = new Random(seed);\n+        IntOpenHashSet numInputs = new IntOpenHashSet();\n+\n+        int batchSize = edges.readInt();\n+        float[] partialDots = new float[batchSize * (1 + negative)];\n+        int dotInc = 0;\n+        for (int position = 0; position < batchSize; position++) {\n+            int src = edges.readInt();\n+            int dst = edges.readInt();\n+            // Skip-Gram model\n+            float[] inputs = layers[src / numNodeOneRow];\n+            int l1 = (src % numNodeOneRow) * dim;\n+            numInputs.add(src);\n+\n+            // Negative sampling\n+            int target;\n+            for (int a = 0; a < negative + 1; a++) {\n+                if (a == 0) {\n+                    target = dst;\n+                } else {\n+                    do {\n+                        target = negativeSeed.nextInt(maxIndex);\n+                    } while (target == src);\n+                }\n+\n+                numInputs.add(target);\n+                float[] outputs = layers[target / numNodeOneRow];\n+                int l2 = (target % numNodeOneRow) * dim;\n+                float f = 0.0f;\n+                for (int b = 0; b < dim; b++) f += inputs[l1 + b] * outputs[l2 + b];\n+                partialDots[dotInc++] = f;\n+            }\n+        }\n+        this.numInputsToUpdate = numInputs.size();\n+        return partialDots;\n     }\n \n-    // update input\n-    ObjectIterator<Int2IntMap.Entry> it = inputIndex.int2IntEntrySet().fastIterator();\n-    while (it.hasNext()) {\n-      Int2IntMap.Entry entry = it.next();\n-      int node = entry.getIntKey();\n-      int offset = entry.getIntValue() * dim;\n-      int divider = inputUpdateCounter.get(node);\n-      int col = (node % numNodeOneRow) * dim;\n-      float[] values = layers[node / numNodeOneRow];\n-      for (int a = 0; a < dim; a++) values[a + col] += inputUpdates[offset + a] / divider;\n+    @Override\n+    public void adjust(ByteBuf dataBuf, int numInputs, int numOutputs) {\n+\n+        // used to accumulate the updates for input vectors\n+        float[] neu1e = new float[dim];\n+        float[] inputUpdates = new float[numInputs * dim];\n+        Int2IntOpenHashMap inputIndex = new Int2IntOpenHashMap();\n+        Int2IntOpenHashMap inputUpdateCounter = new Int2IntOpenHashMap();\n+        Random negativeSeed = new Random(seed);\n+        int batchSize = dataBuf.readInt();\n+\n+        for (int position = 0; position < batchSize; position++) {\n+            int src = dataBuf.readInt();\n+            int dst = dataBuf.readInt();\n+\n+            float[] inputs = layers[src / numNodeOneRow];\n+            int l1 = (src % numNodeOneRow) * dim;\n+\n+            Arrays.fill(neu1e, 0);\n+\n+            // Negative sampling\n+            int target;\n+            for (int d = 0; d < negative + 1; d++) {\n+                if (d == 0) {\n+                    target = dst;\n+                } else {\n+                    do {\n+                        target = negativeSeed.nextInt(maxIndex);\n+                    } while (target == src);\n+                }\n+\n+                float[] outputs = layers[target / numNodeOneRow];\n+                int l2 = (target % numNodeOneRow) * dim;\n+\n+                float g = dataBuf.readFloat();\n+\n+                // accumulate for the hidden layer\n+                for (int a = 0; a < dim; a++) neu1e[a] += g * outputs[a + l2];\n+                // update output layer\n+                merge(inputUpdates, inputIndex, target, inputs, g, l1);\n+                inputUpdateCounter.addTo(target, 1);\n+            }\n+\n+            // update the hidden layer\n+            merge(inputUpdates, inputIndex, src, neu1e, 1, 0);\n+            inputUpdateCounter.addTo(src, 1);\n+        }\n+\n+        // update input\n+        ObjectIterator<Int2IntMap.Entry> it = inputIndex.int2IntEntrySet().fastIterator();\n+        while (it.hasNext()) {\n+            Int2IntMap.Entry entry = it.next();\n+            int node = entry.getIntKey();\n+            int offset = entry.getIntValue() * dim;\n+            int divider = inputUpdateCounter.get(node);\n+            int col = (node % numNodeOneRow) * dim;\n+            float[] values = layers[node / numNodeOneRow];\n+            for (int a = 0; a < dim; a++) values[a + col] += inputUpdates[offset + a] / divider;\n+        }\n     }\n-  }\n }\n",
            "diff_size": 143
        },
        {
            "tool": "naturalize",
            "violations": [
                {
                    "line": "14",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 114).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/naturalize/1/LINEFirstOrderModel.java\nindex 4af089cbb97..c5f3e8401d5 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/naturalize/1/LINEFirstOrderModel.java\n@@ -11,7 +11,6 @@ import java.util.Random;\n \n public class LINEFirstOrderModel extends EmbeddingModel {\n \n-\n   public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow, float[][] layers) {\n     super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n   }\n@@ -37,7 +36,7 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n       int target;\n       for (int a = 0; a < negative + 1; a++) {\n         if (a == 0) target = dst;\n-        else do {\n+  else do {\n           target = negativeSeed.nextInt(maxIndex);\n         } while (target == src);\n \n@@ -45,7 +44,8 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n         float[] outputs = layers[target / numNodeOneRow];\n         int l2 = (target % numNodeOneRow) * dim;\n         float f = 0.0f;\n-        for (int b = 0; b < dim; b++) f += inputs[l1 + b] * outputs[l2 + b];\n+        for (int b = 0; b < dim; b++)\n+  f += inputs[l1 + b] * outputs[l2 + b];\n         partialDots[dotInc++] = f;\n       }\n     }\n@@ -77,7 +77,7 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n       int target;\n       for (int d = 0; d < negative + 1; d++) {\n         if (d == 0) target = dst;\n-        else do {\n+  else do {\n           target = negativeSeed.nextInt(maxIndex);\n         } while (target == src);\n \n@@ -110,4 +110,4 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n       for (int a = 0; a < dim; a++) values[a + col] += inputUpdates[offset + a] / divider;\n     }\n   }\n-}\n+}\n\\ No newline at end of file\n",
            "diff_size": 6
        },
        {
            "tool": "codebuff",
            "violations": [
                {
                    "line": "13",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 114).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/codebuff/1/LINEFirstOrderModel.java\nindex 4af089cbb97..c4245a37e10 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/codebuff/1/LINEFirstOrderModel.java\n@@ -5,23 +5,19 @@ import it.unimi.dsi.fastutil.ints.Int2IntMap;\n import it.unimi.dsi.fastutil.ints.Int2IntOpenHashMap;\n import it.unimi.dsi.fastutil.ints.IntOpenHashSet;\n import it.unimi.dsi.fastutil.objects.ObjectIterator;\n-\n import java.util.Arrays;\n import java.util.Random;\n \n public class LINEFirstOrderModel extends EmbeddingModel {\n \n-\n   public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow, float[][] layers) {\n     super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n   }\n \n   @Override\n   public float[] dot(ByteBuf edges) {\n-\n     Random negativeSeed = new Random(seed);\n     IntOpenHashSet numInputs = new IntOpenHashSet();\n-\n     int batchSize = edges.readInt();\n     float[] partialDots = new float[batchSize * (1 + negative)];\n     int dotInc = 0;\n@@ -34,27 +30,33 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n       numInputs.add(src);\n \n       // Negative sampling\n+\n       int target;\n       for (int a = 0; a < negative + 1; a++) {\n         if (a == 0) target = dst;\n-        else do {\n-          target = negativeSeed.nextInt(maxIndex);\n-        } while (target == src);\n-\n+        else\n+          do {\n+            target = negativeSeed.nextInt(maxIndex);\n+          } while (target == src);\n         numInputs.add(target);\n         float[] outputs = layers[target / numNodeOneRow];\n         int l2 = (target % numNodeOneRow) * dim;\n         float f = 0.0f;\n-        for (int b = 0; b < dim; b++) f += inputs[l1 + b] * outputs[l2 + b];\n+        for (int b = 0; b < dim; b++)\n+          f += inputs[l1 + b] * outputs[l2 + b];\n         partialDots[dotInc++] = f;\n       }\n     }\n+\n+\n+\n     this.numInputsToUpdate = numInputs.size();\n     return partialDots;\n   }\n \n   @Override\n-  public void adjust(ByteBuf dataBuf, int numInputs, int numOutputs) {\n+  public void adjust(\n+    ByteBuf dataBuf, int numInputs, int numOutputs) {\n \n     // used to accumulate the updates for input vectors\n     float[] neu1e = new float[dim];\n@@ -63,31 +65,29 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n     Int2IntOpenHashMap inputUpdateCounter = new Int2IntOpenHashMap();\n     Random negativeSeed = new Random(seed);\n     int batchSize = dataBuf.readInt();\n-\n     for (int position = 0; position < batchSize; position++) {\n       int src = dataBuf.readInt();\n       int dst = dataBuf.readInt();\n-\n       float[] inputs = layers[src / numNodeOneRow];\n       int l1 = (src % numNodeOneRow) * dim;\n-\n       Arrays.fill(neu1e, 0);\n \n       // Negative sampling\n+\n       int target;\n       for (int d = 0; d < negative + 1; d++) {\n         if (d == 0) target = dst;\n-        else do {\n-          target = negativeSeed.nextInt(maxIndex);\n-        } while (target == src);\n-\n+        else\n+          do {\n+            target = negativeSeed.nextInt(maxIndex);\n+          } while (target == src);\n         float[] outputs = layers[target / numNodeOneRow];\n         int l2 = (target % numNodeOneRow) * dim;\n-\n         float g = dataBuf.readFloat();\n \n         // accumulate for the hidden layer\n-        for (int a = 0; a < dim; a++) neu1e[a] += g * outputs[a + l2];\n+        for (int a = 0; a < dim; a++)\n+          neu1e[a] += g * outputs[a + l2];\n         // update output layer\n         merge(inputUpdates, inputIndex, target, inputs, g, l1);\n         inputUpdateCounter.addTo(target, 1);\n@@ -99,6 +99,7 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n     }\n \n     // update input\n+\n     ObjectIterator<Int2IntMap.Entry> it = inputIndex.int2IntEntrySet().fastIterator();\n     while (it.hasNext()) {\n       Int2IntMap.Entry entry = it.next();\n@@ -107,7 +108,9 @@ public class LINEFirstOrderModel extends EmbeddingModel {\n       int divider = inputUpdateCounter.get(node);\n       int col = (node % numNodeOneRow) * dim;\n       float[] values = layers[node / numNodeOneRow];\n-      for (int a = 0; a < dim; a++) values[a + col] += inputUpdates[offset + a] / divider;\n+      for (int a = 0; a < dim; a++)\n+        values[a + col] += inputUpdates[offset + a] / divider;\n     }\n   }\n-}\n+\n+}\n\\ No newline at end of file\n",
            "diff_size": 32
        },
        {
            "tool": "styler_random",
            "violations": [],
            "diff": "diff --git a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/styler/05_predictions/random/files-repaired/1/LINEFirstOrderModel.java\nindex 4af089cbb97..d1cca55afd6 100644\n--- a/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/violations/1/LINEFirstOrderModel.java\n+++ b/home/fernanda/mnt/fernanda/git-styler/styler/src/experiments/projects/Angel-ML-angel/styler/05_predictions/random/files-repaired/1/LINEFirstOrderModel.java\n@@ -11,9 +11,8 @@ import java.util.Random;\n \n public class LINEFirstOrderModel extends EmbeddingModel {\n \n-\n-  public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int numNodeOneRow, float[][] layers) {\n-    super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n+  public LINEFirstOrderModel(int dim, int negative, int seed, int maxIndex, int\n+numNodeOneRow , float [][]layers) {super(dim, negative, seed, maxIndex, numNodeOneRow, layers);\n   }\n \n   @Override\n",
            "diff_size": 3
        },
        {
            "tool": "styler_three_grams",
            "violations": [
                {
                    "line": "15",
                    "severity": "error",
                    "message": "Line is longer than 100 characters (found 114).",
                    "source": "com.puppycrawl.tools.checkstyle.checks.sizes.LineLengthCheck"
                }
            ],
            "diff": "",
            "diff_size": 0
        }
    ],
    "repaired_by": [
        "styler",
        "checkstyle_idea",
        "styler_random"
    ],
    "not_repaired_by": [
        "naturalize",
        "codebuff",
        "styler_three_grams"
    ]
}